---
layout: page
title: Insights
subtitle: When Holmes investigates ðŸ”Ž
---
<div style="text-align: justify">
    The evaluation of various language models yields to serval insights.
    Find more details and further discussions in our <a href= "todo>paper</a>.
    Any questions or wondering about other details? Happy to <a href= "mailto:holmesbenchmark@gmail.com">chat</a>.
</div>

# The Linguistic Competence of Language Models
<div style="text-align: justify">
    Language models clearly better understand *morphology* and *syntax* than *semantics*, *reasoning*, and *discourse*.
    This distinction is evident in morphology and syntax's significantly higher Task Metric (`f1 macro` or `regression`).
    Next, it makes sense to differentiate between the phenomena types (like *morphology* or *discourse*).
    We find they have balanced *Discriminability* scores, which means that none of them dominates the overall ranking.
    *Discriminability* measures the rank correlation of a specific dataset with the overall HolmesðŸ”Ž rankings.
    Finally, the substantial *Selectivity* underlines the validity of our probing setup.
    Compared to training a probe using randomized labels, our probes effectively detect linguistic patterns in the internal representation space of language models.
</div>

![Drag Racing](assets/img/overall.jpg)

# The Effect Language Model Architecture
Language model architecture is a crucial 
![Drag Racing](assets/img/architecture.jpg)

# The Effect of Scaling Language Model Size
Considering th
![Drag Racing](assets/img/scaling.jpg)
