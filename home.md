---
layout: home
title: Holmes
subtitle: Benchmark the Linguistic Competence of Language Models
---

Holmes ðŸ”Ž is a research project focusing on the assessment of the linguistic competence of language models.
Along with the benchmark itself, we provide different resources.

# ðŸ“šBenchmark
The Holmes ðŸ”Ž benchmark features over 200 dataset covering 66 phenomena for *morphology*, *syntax*, *semantics*, *reasoning*, and *discourse*.
Using classifier-based probing, Holmes ðŸ”Ž directly assess the linguistic competence of language models without tangling them with other abilities, like following provided instructions in prompting-based evaluations.

![Drag Racing](assets/img/benchmark.jpg)

# ðŸš€[Leaderboard](https://holmes-leaderboard.streamlit.app)
The **Holmes Leaderboard** provides an interactive overview of evaluating over 50 different language models for Holmes ðŸ”Ž and its counterpart FlashHolmes âš¡ - optimized for efficiency.

# ðŸ”Ž[Interactive Exploration](https://holmes-explorer.streamlit.app)
Using the **Holmes Explorer**, one can delve into more detailed results by comparing single datasets, phenomena or phenomena types.

# ðŸ”¥[Evaluation Code](https://github.com/Holmes-Benchmark/holmes-evaluation)
Enable the fast evaluation of your favorite language model, we provide code to run Holmes ðŸ”Ž or FlashHolmes âš¡ with no more than one command.