---
layout: home
title: Holmes
subtitle: Benchmark the Linguistic Competence of Language Models
---

<div style="text-align:justify">
    Holmes ðŸ”Ž is a research project focusing on the assessment of the linguistic competence of language models regarding morphology, syntax, semantic, reasoning and discourse phenomena.
    Along with the benchmark itself, we provide different resources.
</div>
    <h1>ðŸ“šBenchmark</h1>
    The Holmes ðŸ”Ž benchmark features over 200 dataset covering 66 phenomena for morphology, syntax, semantics, reasoning, and discourse.
    Using classifier-based probing, Holmes ðŸ”Ž directly assess the linguistic competence of language models without tangling them with other abilities, like following provided instructions in prompting-based evaluations.

<img src="assets/img/benchmark.jpg">

    <h1>ðŸš€Leaderboard</h1>
    The **Leaderboard** provides an interactive overview of evaluating over 50 different language models for Holmes ðŸ”Ž and its counterpart FlashHolmes Holmes ðŸ”Ž - optimized for efficiency.

    <h1>ðŸ”ŽInteractive Exploration</h1>
    Using the **Explorer**, one can delve into more detailed results by comparing single datasets, phenomena or phenomena types.

    <h1>ðŸ”¥Evaluation Code</h1>
