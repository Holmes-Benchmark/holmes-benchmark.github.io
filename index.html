---
layout: home
title: Holmes
subtitle: Benchmark the Linguistic Competence of Language Models
---

<div style="text-align:justify">
    Holmes ðŸ”Ž is a research project focusing on the assessment of the linguistic competence of language models regarding morphology, syntax, semantic, reasoning and discourse phenomena.
    Along with the benchmark itself, we provide different resources.
</div>
    <h1>ðŸ“šBenchmark</h1>
    The Holmes ðŸ”Ž benchmark features over 200 dataset covering 66 phenomena for morphology, syntax, semantics, reasoning, and discourse.
    Using classifier-based probing, Holmes ðŸ”Ž directly assess the linguistic competence of language models without tangling them with other abilities, like following provided instructions in prompting-based evaluations.

    <img src="assets/img/benchmark.jpg">

    <h1>ðŸš€<a href="https://holmes-leaderboard.streamlit.app">Leaderboard</a></h1>
    The **Holmes Leaderboard** provides an interactive overview of evaluating over 50 different language models for Holmes ðŸ”Ž and its counterpart FlashHolmes âš¡ - optimized for efficiency.

    <h1>ðŸ”Ž<a href="https://holmes-explorer.streamlit.app">Interactive Exploration</a></h1>
    Using the **Holmes Explorer**, one can delve into more detailed results by comparing single datasets, phenomena or phenomena types.

    <h1>ðŸ”¥<a href="https://github.com/Holmes-Benchmark/holmes-evaluation">Evaluation Code</a></h1>
    Enable the fast evaluation of your favorite language model, we provide code to run Holmes ðŸ”Ž or FlashHolmes âš¡ with no more than one command.